% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/reverse.R
\name{ReverseDiff}
\alias{ReverseDiff}
\alias{reverse_grad}
\alias{reverse_jacobian}
\alias{reverse_hessian}
\alias{reverse_grad_config}
\alias{reverse_jacobian_config}
\alias{reverse_hessian_config}
\alias{reverse_grad_tape}
\alias{reverse_jacobian_tape}
\alias{reverse_hessian_tape}
\alias{reverse_compile}
\title{Wrapper functions for API of \code{ReverseDiff.jl}.}
\usage{
reverse_grad(f_or_tape, input, cfg = NULL, diffresult = NULL,
  debug = TRUE)

reverse_jacobian(f_or_tape, input, cfg = NULL, diffresult = NULL,
  debug = TRUE)

reverse_hessian(f_or_tape, input, cfg = NULL, diffresult = NULL,
  debug = TRUE)

reverse_grad_config(input, diffresult = NULL)

reverse_jacobian_config(input, diffresult = NULL)

reverse_hessian_config(input, diffresult = NULL)

reverse_grad_tape(f, input, cfg = NULL)

reverse_jacobian_tape(f, input, cfg = NULL)

reverse_hessian_tape(f, input, cfg = NULL)

reverse_compile(tape)
}
\arguments{
\item{f_or_tape}{the target function \code{f} or the tape recording execution trace of \code{f}.}

\item{input}{the point where you take the gradient, jacobian and hessian.
Note that it should be a a vector of length greater than 1.
If you want to calulate the derivative of a function, you can considering using \code{forward_deriv}.}

\item{cfg}{Config objects which contains the preallocated tape and work buffers
used by reverse mode automatic differentiation.
\code{ReverseDiff}'s API methods will allocate the Config object automatically by default,
but you can preallocate them yourself and reuse them for subsequent calls to reduce memory usage.}

\item{diffresult}{Optional DiffResult object to store the derivative information.}

\item{debug}{Whether to use the wrapper functions under debug mode.
With the debug mode, users can have more informative error messages.
Without the debug mode, the wrapper functions will be more performant.}

\item{f}{the function you want to calulate the gradient, jacobian and hessian.
Note that \code{f(x)} should be a scalar for \code{grad} and \code{hessian},
a vector of length greater than 1 for \code{jacobian}.}

\item{tape}{the object to record the target function's execution trace used by
reverse mode automatic differentiation.
In many cases, pre-recording and pre-compiling a reusable tape for a given function and
differentiation operation can improve the performance of reverse mode automatic differentiation.
Note that pre-recording a tape can only capture the the execution trace of the target function
with the given input values.
In other words, the tape cannot any re-enact branching behavior that depends on the input values.
If the target functions contain control flow based on the input values, be careful or not to
use tape-related APIs.}
}
\value{
\code{reverse_grad}, \code{reverse_jacobian} and \code{reverse_hessian} return
the gradient, jacobian and hessian of \code{f} or \code{tape} correspondingly evaluated at \code{input}.
\code{reverse_grad_config}, \code{reverse_jacobian_config} and \code{reverse_hessian_config}
return Config instances containing the preallocated tape and work buffers used by
reverse mode automatic differentiation.
\code{reverse_grad_tape}, \code{reverse_jacobian_tape} and \code{reverse_hessian_tape}
return Tape instances containing the the execution trace of the target function
with the given input values.
}
\description{
Wrapper functions for API of \code{ReverseDiff.jl} at
\url{http://www.juliadiff.org/ReverseDiff.jl/api/}.
These functions can help you calculate gradient, jacobian and hessian
for your functions using reverse mode automatic differentiation.
For more details, see \url{http://www.juliadiff.org/ReverseDiff.jl/api/}.
}
